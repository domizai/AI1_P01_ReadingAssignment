<style>
    :root {
        --color-text: #001561;
        --color-background: #fff;
        --color-link: #0382d0;
    }

    html {
        scroll-behavior: smooth;
    }

    body {
        font-family: Georgia, serif;
        background-color: var(--color-background);
        color: var(--color-text);
        font-size: 19px;
        line-height: 1.2;
        padding-top: 3rem;
        padding-bottom: 6rem;
        max-width: 680px;
    }

    a:visited, a:link, a:hover, a:active {
        color: var(--color-link);
    }

    p, li {
        font-size: 1.2rem;
        line-height: 1.6;
        max-width: 100%;
    }

    ul {
        max-width: 100%;
    }

    li {
        margin-bottom: 0.5em;
    }

    h1, h2, h3 {
        font-weight: bold;
        margin-top: 2em;
    }

    h1 {
        font-size: 1.8em;
    }

    h2 {
        font-size: 1.4em;
    }

    h3 {
        font-size: 1.0em;
    }

    .references, .references > p, address, time, a[href^="#"] {
        font-family: Arial, sans-serif;
        font-size: 0.93rem;
        font-style: normal;
    }

    .references > p {
        margin-bottom: 1em;
    }

    .authors {
        font-weight: bold;
        line-height: 1.7;
    }

    .byline {
        margin-bottom: 2.5em;
    }
</style>

# AI as Normal Technology:<br>Three Scenarios for the Coming Years

<div class="byline">
    <address class="authors">By Sercan Ay und Dominique Schmitz</address>
    <address>ZHAW Zurich University of Applied Sciences, Switzerland</address>
    <time>30.09.2025</time>
</div>

In their essay 'AI as Normal Technology', Narayanan and Kapoor argue that artificial intelligence (AI) should not be primarily understood as an imminent threat from future superintelligence. Rather, they suggest that it should be viewed as a 'normal' technology, akin to the advent of electricity or the internet [[1]](#ref1). This perspective challenges the extreme scenarios that dominate the headlines, whether utopian promises or dystopian collapse. Viewing AI as a normal technology establishes more realistic expectations: technological adoption takes time, regulations impede progress and advances are implemented incrementally.

In this blog post, we present three theses concerning the future development of AI, based on the arguments of Narayanan and Kapoor and supported by recent research. Below are some key points from the article that serve as the basis for our arguments:

- Diffusion (Adoption) is limited by the speed of humans. Adoption is about software use, not availability.
- Innovation is about products that consumers and businesses can use. Technical advances in AI have been rapid, but we must differentiate AI methods from applications.
- Benchmarks do not measure real-world utility.
- Humans will adapt and will focus on tasks that are not yet automated, perhaps tasks that do not exist today.
- Transformation will be primarily driven by market forces. Market forces will provide an adequate incentive for safety regulation.
- Market success has been strongly correlated with safety. But the slow pace of regulation might be a problem.
- Defense against superintelligence requires humanity to unite.
- Intelligence is not clearly defined. In the context of AI, it refers to abilities and power. More abilities mean more power and thus a potential loss of control by humans.
- The risk of bioweapons is real. Capable AI models are already widespread, with many organizations sharing their complete code, data, and training methodologies.

## Thesis 1: AI as an Everyday Assistant

AI will soon become an integral part of everyday life. In the field of transportation, for example, automated driving systems, intelligent navigation and smart traffic management will make journeys safer and more efficient.

In the private sphere, AI assistants will help with shopping, compare prices and automatically order missing items. When it comes to travel planning, they will suggest flights and hotels, or even remind us of birthdays and suggest gift ideas. Some of these functions may initially feel intrusive, such as an AI predicting a pregnancy and adjusting shopping lists accordingly. However, even such pre-emptive features will gradually become normalised, just as other modern technologies once did. [[2]](#ref2)

Personal digital assistants will have the strongest impact. Smartphones will communicate with each other to coordinate emails, invoices and appointments. Smart household devices such as washing machines and vacuum cleaners will synchronise autonomously. Together, these systems will form an integrated digital assistant that structures everyday routines. Advances in robotics are also expected, with general-purpose humanoid robots entering households within the next five years [[3]](#ref3).

There will also be some developments in the medical field. For example, Microsoft has developed an AI system that works like a virtual team of doctors and achieved 85.5% diagnostic accuracy in 304 real clinical case studies published in the New England Journal of Medicine (NEJM). This is significantly more than doctors, who achieve around 20%. The method is faster, more accurate and cheaper than traditional diagnostics, but is still considered experimental as it has not yet been clinically tested. [[4]](#ref4)

In all these scenarios, responsibility remains with humans, but much of the work shifts to AI systems. Therefore, rather than replacing human capabilities, AI will become a reliable companion that supports and relieves us.

## Thesis 2: AI Integrates Slowly into Society

Innovation always takes time to spread. Although electrification was available early on, it took decades for factories to adapt fully and realise productivity gains. The same pattern applies to AI: despite frequent media hype about 'quantum leaps', its integration into businesses, schools and administrations will be gradual. [[1]](#ref1)

Regulation plays a major role. While it mitigates risks, it also slows down adoption. This deceleration is not necessarily negative but allows for safer and more controlled integration into existing structures. [[5]](#ref5)

Another factor is benchmarks. Technical tests often measure narrow capabilities that cannot easily be translated into real-world reliability. A model that outperforms humans in exams is not yet a reliable doctor or employee. Overinterpreting benchmarks can create inflated expectations and fuel narratives of rapid progress towards superintelligence. [[1]](#ref1)

A more realistic scenario is therefore incremental evolution: over the next five years, AI will steadily become integrated into more areas of life. Unspectacular, but persistent. Rather than a sudden revolution, we can expect an evolution that enables technology and society to adapt to each other.

## Thesis 3: The Risk of Dependence

While AI will make everyday life easier, it also carries the risk of increasing reliance. Even today, many tasks such as writing, summarising and problem-solving are outsourced to AI rather than being carried out by humans themselves. Over the next five years, basic skills may erode as people increasingly rely on AI to make decisions for them, gradually losing autonomy. [[6]](#ref6)

This dependence increases susceptibility to manipulation. AI systems enable new forms of influence, such as fake speeches, hyper-realistic images and videos, and targeted disinformation campaigns on social media [[7]](#ref7). Narayanan and Kapoor emphasise that the true risks do not lie in a 'Skynet' scenario, but rather in systemic vulnerabilities such as inequality and human misuse. The pollution of the information ecosystem and the decline of independent journalism are realistic dangers.

Therefore, while AI is likely to enrich our lives, it may also create new dependencies. These dependencies could lead to a loss of skills and make society more vulnerable to manipulation. The greatest threat is not a rebellious superintelligence, but rather how we handle the technology ourselves.

## Discussion

Intelligence involves solving and recognising problems. While current large language models (LLMs) excel at solving explicit tasks, they cannot autonomously detect new problems in unstructured environments.

Recent surveys on memory in LLMs confirm these limitations. Current architectures have restricted context windows and lack robust long-term memory [[8]](#ref8)[[9]](#ref9). Other studies argue that self-evolving AI would require memory mechanisms that are fundamentally new and go beyond today's transformer models [[10]](#ref10).

Superintelligence remains distant as long as LLMs cannot sustain long-term memory and autonomous problem recognition. Today's systems are advanced pattern recognisers, not genuine intelligent systems. AI should therefore be understood as a tool to augment human capabilities, rather than a replacement for human judgement.

## Conclusion

We consider scenarios 1 and 2 to be the most likely. Over the next five years, AI is set to become an integral part of our daily lives, permeating transport systems, digital assistants and consumer applications. However, integration will be gradual, hindered by regulation and the pace of societal adaptation.

The risk of dependence and manipulation in scenario 3 is real, but not inevitable. Whether or not it becomes a threat depends on how we shape regulation, education and the responsible use of AI.

If we prioritise transparency, security and creativity, AI could enrich our lives without undermining our self-determination.

<br>

<div class="references">

## References

<a id="ref1"></a>\[1\] A. Narayanan und S. Kapoor, «An alternative to the vision of AI as a potential superintelligence».

<a id="ref2"></a>\[2\] «KI-Ferienplanung: Nie war Reisen einfacher», 20 Minuten. Zugegriffen: 30. September 2025. \[Online\]. Verfügbar unter: <https://www.20min.ch/story/prompt-der-woche-ki-plant-deine-ferienreise-103363987>

<a id="ref3"></a>\[3\] ColdFusion, _Forget AI, The Robots Are Coming!_, (16. September 2025). Zugegriffen: 30. September 2025. \[Online Video\]. Verfügbar unter: <https://www.youtube.com/watch?v=Eys5oQabMF8>

<a id="ref4"></a>\[4\] «The Path to Medical Superintelligence», Microsoft AI. Zugegriffen: 3. Juli 2025. \[Online\]. Verfügbar unter: <https://microsoft.ai/new/the-path-to-medical-superintelligence/>

<a id="ref5"></a>\[5\] «Zürich testet AI, die Haus­aufgaben kontrolliert - Lehrerin begeistert», Tages-Anzeiger. Zugegriffen: 30. September 2025. \[Online\]. Verfügbar unter: <https://www.tagesanzeiger.ch/ki-in-der-schule-statt-der-lehrerin-kontrolliert-die-app-die-hausaufgaben-666176190812>

<a id="ref6"></a>\[6\] I. Pohrebniyak, «LLM Limitations, Risks, Challenges and Future», Master of Code Global. Zugegriffen: 30. September 2025. \[Online\]. Verfügbar unter: <https://masterofcode.com/blog/generative-ai-limitations-risks-and-future-directions-of-llms>

<a id="ref7"></a>\[7\] deutschlandfunk.de, «Deepfakes - Wie mit KI Wahlen manipuliert werden könnten», Deutschlandfunk. Zugegriffen: 30. September 2025. \[Online\]. Verfügbar unter: <https://www.deutschlandfunk.de/ki-wahlen-manipulation-kuenstliche-intelligenz-fake-news-deepfakes-100.html>

<a id="ref8"></a>\[8\] M. Hwang, Y. Zheng, Y. Cho, und Y. Jiang, «AI Applications for Chronic Condition Self-Management: Scoping Review», _J. Med. Internet Res._, Bd. 27, Nr. 1, S. e59632, Apr. 2025, doi: 10.2196/59632.

<a id="ref9"></a>\[9\] S. Chan, P. Pataranutaporn, A. Suri, W. Zulfikar, P. Maes, und E. F. Loftus, «Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews», 8. August 2024, _arXiv_: arXiv:2408.04681. doi: 10.48550/arXiv.2408.04681.

<a id="ref10"></a>\[10\] «Long Term Memory : The Foundation of AI Self-Evolution». Zugegriffen: 30. September 2025. \[Online\]. Verfügbar unter: <https://arxiv.org/html/2410.15665v2>

</div>